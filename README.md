# 《精通数据科学：从线性回归到深度学习》配套代码

**《精通数据科学：从线性回归到深度学习》一书的配套代码和数据**

这个分支和master分支的区别是，该分支的代码更加工整，符合PEP 8的规范（由脚本./dev/lint-python来保证代码规范）。

本书由人民邮电出版社出版，网购地址为：

* [京东](https://item.jd.com/12346637.html)
* [当当](http://product.dangdang.com/25269988.html)

本书还配套免费的视频课程，观看地址为：

* [网易云课堂](https://study.163.com/course/introduction/1006187021.htm)

如果发现书中有纰漏之处，请在[这里勘误](https://www.epubit.com/book/detail/22985)，谢谢大家。

如果大家对本书有赞赏、建议、批评之声，请在[豆瓣](https://book.douban.com/subject/30217266/)上留下你们的看法，再次谢谢大家。

## 作者想说的话

即使有严重的自夸嫌疑，但我还是想说：这是一本非常不错的书，推荐大家购买。

李国杰院士和韩家炜教授在读过这本书之后，亲自为其作序，在此再次向两位大佬表示感谢。


## 目录
- 第1章  数据科学概述	
	- 1.1　挑战
	- 1.2　机器学习	- 1.3　统计模型	- 1.4　关于本书- 第2章  Python安装指南与简介：告别空谈	- 2.1　Python简介	- 2.2　Python安装	- 2.3　Python上手实践	- 2.4　本章小结- 第3章  数学基础：恼人但又不可或缺的知识	- 3.1　矩阵和向量空间	- 3.2　概率：量化随机	- 3.3　微积分	- 3.4　本章小结- 第4章  线性回归：模型之母	- 4.1　一个简单的例子	- 4.2　上手实践：模型实现	- 4.3　模型陷阱	- 4.4　模型持久化	- 4.5　本章小结- 第5章  逻辑回归：隐藏因子	- 5.1　二元分类问题：是与否	- 5.2　上手实践：模型实现	- 5.3　评估模型效果：孰优孰劣	- 5.4　多元分类问题：超越是与否	- 5.5　非均衡数据集	- 5.6　本章小结- 第6章  工程实现：计算机是怎么算的	- 6.1　算法思路：模拟滚动	- 6.2　数值求解：梯度下降法	- 6.3　上手实践：代码实现	- 6.4　更优化的算法：随机梯度下降法	- 6.5　本章小结- 第7章  计量经济学的启示：他山之石	- 7.1　定量与定性：变量的数学运算合理吗	- 7.2　定性变量的处理	- 7.3　定量变量的处理	- 7.4　显著性	- 7.5　多重共线性：多变量的烦恼	- 7.6　内生性：变化来自何处	- 7.7　本章小结- 第8章  监督式学习： 目标明确	- 8.1　支持向量学习机	- 8.2　核函数	- 8.3　决策树	- 8.4　树的集成	- 8.5　本章小结- 第9章  生成式模型：量化信息的价值	- 9.1　贝叶斯框架	- 9.2　朴素贝叶斯	- 9.3　判别分析	- 9.4　隐马尔可夫模型	- 9.5　本章小结- 第10章  非监督学习：聚类与降维	- 10.1　K-means	- 10.2　其他聚类模型	- 10.3　Pipeline	- 10.4　主成分分析	- 10.5　奇异值分解	- 10.6　本章小结- 第11章  分布式机器学习：集体力量	- 11.1　Spark简介	- 11.2　最优化问题的分布式解法	- 11.3　大数据模型的两个维度	- 11.4　开源工具的另一面	- 11.5　本章小结- 第12章  神经网络：模拟人的大脑	- 12.1　神经元	- 12.2　神经网络	- 12.3　反向传播算法	- 12.4　提高神经网络的学习效率	- 12.5　本章小结- 第13章  深度学习：继续探索	- 13.1　利用神经网络识别数字	- 13.2　卷积神经网络	- 13.3　其他深度学习模型	- 13.4　本章小结	


## 代码说明

针对技术书籍，最好的阅读方法是对照每一章的示例代码，动手实现所讨论的模型。这样会极大加深自己对模型的理解和实践能力，否则就会像读小说一样，阅读时感觉不错，但实际使用时就无从下手了。

若想要使用这份代码，请先按照本书第2章和第11章的指南，安装相关的开源软件。需要注意的是，为了节省篇幅、突出重点，正文中所展示的代码是基于Linux系统下的Python 2.7，而配套代码则兼容Python 3和Windows系统。